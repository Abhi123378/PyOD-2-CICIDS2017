
    <style>
    h1, h2, h3, h4, h5, h6 {
        text-align: left !important;
    }
    </style>
    
    <html>
    <head>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; }
            h2 { text-align: center; font-size: 20pt; }
            img { display: block; margin: 20px auto; max-width: 90%; }
        </style>
    </head>
    <body>
    <h3>LLM-Augmented Model Selection and Advisory Report for MNIST</h3>

<h4>1. Executive Summary:</h4>

<p>This report evaluates the performance of various anomaly detection models on the MNIST dataset using a combination of symbolic scoring and empirical validation metrics. The dataset is characterized by a large sample size, medium dimensionality, and significant imbalance, with high skewness and kurtosis. The models analyzed include IForest, LUNAR, MO<em>GAAL, SO</em>GAAL, and LOF.</p>

<h4>2. Introduction: Methodology Behind the Recommendation</h4>

<p>The AutoModelAdvisor pipeline integrates symbolic reasoning with empirical validation to rank models. Symbolic scores are derived from a model's theoretical suitability for the dataset's characteristics, while empirical metrics provide a performance-based ranking.</p>

<h4>3. Dataset Overview and Key Characteristics</h4>

<ul>
<li><strong>Sample Size</strong>: 7603</li>
<li><strong>Features</strong>: 100</li>
<li><strong>Anomaly Ratio</strong>: 9.21%</li>
<li><strong>Skewness</strong>: High (avg 16.50)</li>
<li><strong>Kurtosis</strong>: High (avg 1078.59)</li>
<li><strong>Imbalance</strong>: Significant</li>
</ul>

<h4>4. Symbolic Scoring vs. Empirical Evaluation: A Comparative Analysis</h4>

<p>The symbolic scores suggest IForest as the top model, followed by LUNAR, MO<em>GAAL, and SO</em>GAAL, with LOF ranked lowest. However, empirical metrics provide a different perspective:</p>

<ul>
<li><p><strong>IForest</strong>: Highest symbolic score (4.2) and ROC AUC (0.7835), indicating strong theoretical and empirical performance. However, it ranks lower in F1 Minority (4th) and Accuracy (4th), suggesting potential issues with minority class detection.</p></li>
<li><p><strong>LUNAR</strong>: Despite a lower symbolic score (3.1), it excels empirically with the highest F1 Minority (0.3765), Precision, Recall, and Accuracy (0.8802). This indicates robust performance in detecting anomalies, especially in imbalanced conditions.</p></li>
<li><p><strong>MO_GAAL</strong>: Matches LUNAR in symbolic score (3.1) but shows weaker empirical results with lower ROC AUC (0.7184) and F1 Minority (0.2709), indicating less effective anomaly detection.</p></li>
<li><p><strong>SO_GAAL</strong>: Despite a symbolic score of 3.1, it performs poorly across all empirical metrics, particularly ROC AUC (0.6012) and F1 Minority (0.2006), suggesting a mismatch between symbolic expectations and actual performance.</p></li>
<li><p><strong>LOF</strong>: Lowest symbolic score (2.0) but performs reasonably well empirically, with the second-highest F1 Minority (0.2921) and Accuracy (0.8712), indicating it may be underestimated by symbolic scoring.</p></li>
</ul>

<h4>5. Model Ranking Summary Analysis</h4>

<p>The empirical evaluation highlights LUNAR as the most effective model for this dataset, particularly in handling imbalanced data. IForest, while theoretically strong, may require adjustments to improve minority class detection. MO<em>GAAL and SO</em>GAAL show limitations, possibly due to their reliance on generative approaches that may not suit the dataset's characteristics. LOF, despite a low symbolic score, demonstrates competitive empirical performance.</p>

<h4>6. Visual Insights: Heatmap and Grouped Bar Plots Analysis</h4>

<p>The heatmap and bar plots provide a visual comparison of model performances across different metrics, highlighting the strengths and weaknesses of each model in relation to the dataset's characteristics.</p>

<h4>7. LLM-Informed Recommendation and Justification</h4>

<p>Based on the analysis, LUNAR is recommended for deployment due to its superior empirical performance, particularly in F1 Minority and overall accuracy. IForest is a strong alternative, provided its minority class detection can be improved.</p>

<h4>8. Data Preprocessing &amp; Optimization Recommendations</h4>

<p>Consider techniques to enhance minority class detection for IForest, such as adjusting decision thresholds or employing ensemble methods to boost performance.</p>

<h4>9. Hyperparameter Tuning and Guidance for Top Models</h4>

<p>Further tuning of LUNAR and IForest is advised to optimize their performance, focusing on parameters that influence sensitivity to anomalies and class imbalance.</p>

<h4>10. Final Recommendation and Deployment Readiness</h4>

<p>LUNAR is ready for deployment, with IForest as a secondary option pending optimization. Continuous monitoring and periodic re-evaluation are recommended to ensure sustained performance.</p>

<h4>11. Annexure</h4>

<p>Additional data, methodology details, and extended analysis are available in the annexure for further reference.</p>

    <h2>Model Evaluation Table</h2>
    <img src="file:////home/exouser/Downloads/UofACP/outputs/llm_inputs/mnist_llm_eval.png" />
    <h2>Model Evaluation Heatmap</h2>
    <img src="file:////home/exouser/Downloads/UofACP/outputs/llm_inputs/heatmaps/mnist_rank_heatmap.png" />
    <h2>Model-wise Multi-Metric Rankings</h2>
    <img src="file:////home/exouser/Downloads/UofACP/outputs/llm_inputs/graphs/mnist_model_wise_multi_metric_rankings.png" />
    </body>
    </html>
    