
    <style>
    h1, h2, h3, h4, h5, h6 {
        text-align: left !important;
    }
    </style>
    
    <html>
    <head>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; }
            h2 { text-align: center; font-size: 20pt; }
            img { display: block; margin: 20px auto; max-width: 90%; }
        </style>
    </head>
    <body>
    <h3>LLM-Augmented Model Selection and Advisory Report for Arrhythmia Dataset</h3>

<h4>1. Executive Summary:</h4>

<p>This report evaluates the performance of various anomaly detection models on the arrhythmia dataset, characterized by small sample size, high dimensionality, and significant class imbalance. The analysis integrates symbolic reasoning with empirical validation to provide a comprehensive assessment of model efficacy.</p>

<h4>2. Introduction: Methodology Behind the Recommendation</h4>

<p>The AutoModelAdvisor pipeline combines symbolic scoring, which assesses models based on theoretical and heuristic criteria, with empirical metrics derived from actual model performance on the dataset. This dual approach ensures a balanced evaluation, capturing both theoretical potential and practical effectiveness.</p>

<h4>3. Dataset Overview and Key Characteristics</h4>

<p>The arrhythmia dataset is marked by:
- <strong>Small Sample Size</strong>: 452 samples
- <strong>High Dimensionality</strong>: 274 features
- <strong>Imbalanced Classes</strong>: Anomaly ratio of 14.6%
- <strong>High Skewness and Kurtosis</strong>: Average skewness of 6.18 and kurtosis of 85.19
- <strong>No Missing Values</strong>: Clean data with a missing value ratio of 0%
- <strong>Structured Data</strong>: Suitable for structured anomaly detection models</p>

<h4>4. Symbolic Scoring vs. Empirical Evaluation: A Comparative Analysis</h4>

<p>The symbolic scores rank models based on theoretical suitability for the dataset's characteristics, while empirical metrics provide a performance-based ranking. Discrepancies between these rankings can highlight areas where theoretical expectations do not align with practical outcomes.</p>

<h4>5. Model Ranking Summary Analysis</h4>

<ul>
<li><p><strong>IForest</strong>: Symbolically ranked first with a score of 4.5, it also leads empirically across all metrics, indicating strong alignment between theoretical and practical performance. Its high ROC AUC (0.7914) and F1 Minority (0.4286) suggest it balances precision and recall effectively, crucial for imbalanced datasets.</p></li>
<li><p><strong>LUNAR</strong>: Second in both symbolic and empirical rankings, with a symbolic score of 3.4. It shows slightly lower performance than IForest but maintains a good balance between precision (0.5) and recall (0.3485), making it a robust alternative.</p></li>
<li><p><strong>DeepSVDD</strong>: Despite a symbolic rank of 3, its empirical performance is weaker, particularly in ROC AUC (0.7511) and F1 Minority (0.3393). This suggests potential overfitting or inefficiency in handling high dimensionality.</p></li>
<li><p><strong>AutoEncoder</strong>: Ranked fourth symbolically, it surprisingly outperforms DeepSVDD in ROC AUC (0.7656) but suffers in F1 Minority (0.2857), indicating challenges in capturing minority class nuances.</p></li>
<li><p><strong>SO_GAAL</strong>: Tied symbolically with AutoEncoder at rank 4, it ranks last empirically across all metrics. Its low ROC AUC (0.6291) and F1 Minority (0.2679) reflect poor anomaly detection capability, possibly due to its simplistic approach not suited for high-dimensional data.</p></li>
</ul>

<h4>6. Visual Insights: Heatmap and Grouped Bar Plots Analysis</h4>

<p>The heatmap and bar plots illustrate the comparative performance of models across key metrics. IForest consistently shows the highest scores, reinforcing its empirical dominance. LUNAR follows closely, while DeepSVDD and AutoEncoder show mixed results, and SO_GAAL lags significantly.</p>

<h4>7. LLM-Informed Recommendation and Justification</h4>

<p>Based on the analysis, IForest is recommended for deployment due to its superior performance across both symbolic and empirical evaluations. LUNAR is a viable backup, offering a balance between precision and recall. DeepSVDD and AutoEncoder require further optimization, while SO_GAAL is not recommended for this dataset.</p>

<h4>8. Data Preprocessing &amp; Optimization Recommendations</h4>

<ul>
<li><strong>Feature Selection</strong>: Reduce dimensionality to enhance model efficiency, particularly for DeepSVDD and AutoEncoder.</li>
<li><strong>Balancing Techniques</strong>: Implement SMOTE or similar methods to address class imbalance, improving recall.</li>
</ul>

<h4>9. Hyperparameter Tuning and Guidance for Top Models</h4>

<ul>
<li><strong>IForest</strong>: Fine-tune the number of estimators and max samples for optimal performance.</li>
<li><strong>LUNAR</strong>: Adjust learning rates and batch sizes to enhance precision and recall balance.</li>
</ul>

<h4>10. Final Recommendation and Deployment Readiness</h4>

<p>Deploy IForest for real-time anomaly detection in the arrhythmia dataset, with LUNAR as a secondary option. Ensure continuous monitoring and periodic retraining to adapt to data shifts.</p>

<h4>11. Annexure</h4>

<p>Detailed metric tables, heatmaps, and bar plots are included for further reference and validation of the analysis.</p>

    <h2>Model Evaluation Table</h2>
    <img src="file:////home/exouser/Downloads/UofACP/outputs/llm_inputs/arrhythmia_llm_eval.png" />
    <h2>Model Evaluation Heatmap</h2>
    <img src="file:////home/exouser/Downloads/UofACP/outputs/llm_inputs/heatmaps/arrhythmia_rank_heatmap.png" />
    <h2>Model-wise Multi-Metric Rankings</h2>
    <img src="file:////home/exouser/Downloads/UofACP/outputs/llm_inputs/graphs/arrhythmia_model_wise_multi_metric_rankings.png" />
    </body>
    </html>
    